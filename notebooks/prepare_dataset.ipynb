{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5932b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057f7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f25957",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_file = \"../../data/astral-scopedom-seqres-gd-sel-gs-bib-95-2.08.fa\"\n",
    "scope_pattern = re.compile(\"[abcdefghijkl]\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac4076b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g.101.1.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_header = \">d5lqwy_ g.101.1.1 (Y:) Pre-mRNA splicing factor Phf5 / Rds3 {Baker's yeast (Saccharomyces cerevisiae) [TaxId: 4932]}\"\n",
    "scope_pattern.search(test_header).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c0f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file):\n",
    "    sequences = []\n",
    "    scope_codes = []\n",
    "\n",
    "    with open(data_file, \"r\") as fin:\n",
    "        scope_code = \"\"\n",
    "        sequence = \"\"\n",
    "        for line in fin:\n",
    "            if line.startswith(\">\"):\n",
    "                sequences.append(sequence)\n",
    "                scope_codes.append(scope_code)\n",
    "\n",
    "                sequence = \"\"\n",
    "                scope_code = \"\"\n",
    "\n",
    "                header = line.strip()\n",
    "                m = scope_pattern.search(header)\n",
    "                if m is not None:\n",
    "                    scope_code = m.group(0)\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "\n",
    "    sequences = sequences[1:]\n",
    "    scope_codes = scope_codes[1:]\n",
    "    \n",
    "    return sequences, scope_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a59b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scope_similarity_level(code1, code2):\n",
    "    split_code1 = code1.split(\".\")\n",
    "    split_code2 = code2.split(\".\")\n",
    "    for i in range(4,0,-1):\n",
    "        if split_code1[:i] == split_code2[:i]:\n",
    "            return \".\".join(split_code1[:i]), i\n",
    "    return \"\", 0 \n",
    "\n",
    "def get_scope_level(scope_code):\n",
    "    return len(scope_code.split(\".\"))\n",
    "        \n",
    "def generate_scope_pairs(scope_codes):\n",
    "    scope_pairs = defaultdict(list)\n",
    "    for i, scope_codei in enumerate(scope_codes):\n",
    "        for j, scope_codej in enumerate(scope_codes[i+1:]):\n",
    "            similarity_code, _ = get_scope_similarity_level(scope_codei, scope_codej)\n",
    "            scope_pairs[similarity_code].append((i, j+i+1))\n",
    "    return dict(scope_pairs)\n",
    "\n",
    "def get_scope_level_pdf(scope_pairs):\n",
    "    level_distribution = defaultdict(int)\n",
    "    for scope_code, pairs in scope_pairs.items():\n",
    "        if scope_code == \"\":\n",
    "            level_distribution[0] += len(pairs)\n",
    "        else:\n",
    "            level_distribution[get_scope_level(scope_code)] += len(pairs)\n",
    "            \n",
    "    normalization_constant = sum(level_distribution.values())\n",
    "    \n",
    "    for scope_level, v in level_distribution.items():\n",
    "        level_distribution[scope_level] /= normalization_constant\n",
    "        \n",
    "    return level_distribution, normalization_constant\n",
    "\n",
    "def compute_scope_pair_cdf(scope_level_pairs, smoothing_func):\n",
    "    scope_pdf = list()\n",
    "    sum_npairs = 0\n",
    "    for scope_level, pairs in scope_level_pairs.items():\n",
    "        npairs = len(pairs)\n",
    "        sum_npairs += npairs\n",
    "        scope_pdf.append((scope_level, smoothing_func(npairs)))\n",
    "        \n",
    "    normalization_constant = sum([i[1] for i in scope_pdf])\n",
    "    \n",
    "    scope_pdf = [(k,v/normalization_constant) for k, v in scope_pdf]\n",
    "   \n",
    "    cdf = np.cumsum([i[1] for i in scope_pdf])\n",
    "    scope_cdf = [(k,v) for k, v in zip([i[0] for i in scope_pdf], cdf)]\n",
    "\n",
    "    return scope_cdf, scope_pdf\n",
    "\n",
    "def get_sampled_element(cdf):\n",
    "    a = np.random.uniform(0, 1)\n",
    "    return np.argmax(cdf>=a)\n",
    "\n",
    "def run_sampling(cdf, n=5000):\n",
    "    for k in np.arange(n):\n",
    "        yield get_sampled_element(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5db02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a.1.10.100', 4)\n",
      "('a.1.10', 3)\n",
      "('a.1', 2)\n",
      "('a', 1)\n",
      "('', 0)\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(get_scope_similarity_level(\"a.1.10.100\", \"a.1.10.100\"))\n",
    "print(get_scope_similarity_level(\"a.1.10.100\", \"a.1.10.101\"))\n",
    "print(get_scope_similarity_level(\"a.1.10.100\", \"a.1.11.101\"))\n",
    "print(get_scope_similarity_level(\"a.1.10.100\", \"a.0.11.101\"))\n",
    "print(get_scope_similarity_level(\"a.1.10.100\", \"b.1.10.100\"))\n",
    "print(get_scope_level(\"a.1.10.100\"))\n",
    "print(get_scope_level(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05992f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, scope_codes = load_data(scope_file)\n",
    "sequences_train, sequences_test, scope_codes_train, scope_codes_test = train_test_split(sequences, scope_codes, test_size=0.1)\n",
    "scope_pairs_train = generate_scope_pairs(scope_codes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac059997",
   "metadata": {},
   "outputs": [],
   "source": [
    "del scope_pairs_train[0]\n",
    "del scope_pairs_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419ed904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510161653 510161653.0\n"
     ]
    }
   ],
   "source": [
    "scope_level_pdf, normalization_constant = get_scope_level_pdf(scope_pairs_train)\n",
    "print(normalization_constant, len(sequences_train)*(len(sequences_train)-1)/2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73360b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {1: 0.19767118011905924,\n",
       "             0: 0.7778375377029759,\n",
       "             3: 0.009940004251946393,\n",
       "             4: 0.00707713521541377,\n",
       "             2: 0.007474142710604711})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_level_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05756ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_pair_cdf_train, scope_pair_pdf_train = compute_scope_pair_cdf(scope_pairs_train, lambda x: np.power(x, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dbd6bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsets = 100\n",
    "for seti in range(nsets):\n",
    "    with open(f\"../../data/train_set_{seti}.tsv\", \"w\") as fout:\n",
    "        tsvwriter = csv.writer(fout, delimiter='\\t')\n",
    "        for i in run_sampling(np.array([i[1] for i in scope_pair_cdf_train]), n=100000):\n",
    "            scope_code, _ = scope_pair_cdf_train[i]\n",
    "            pairs = scope_pairs_train[scope_code]\n",
    "            pairi = np.random.randint(0,len(pairs), None)\n",
    "            i1, i2 = pairs[pairi]\n",
    "            common_scope_code, common_level = get_scope_similarity_level(scope_codes_train[i1],\n",
    "                                                                         scope_codes_train[i2])\n",
    "            tpl = (sequences_train[i1], \n",
    "                    sequences_train[i2], \n",
    "                    scope_codes_train[i1], \n",
    "                    scope_codes_train[i2],\n",
    "                   common_level,\n",
    "                  )\n",
    "            tsvwriter.writerow(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ecd7bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {0: 0.23309999999999065,\n",
       "             1: 0.2560999999999881,\n",
       "             3: 0.18849999999999556,\n",
       "             4: 0.23059999999999092,\n",
       "             2: 0.0917000000000016})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_distribution = defaultdict(int)\n",
    "with open(\"../../data/train_set_0.tsv\", \"r\") as fin:\n",
    "    tsvreader = csv.csvreader(fin, delimiter=\"\\t\")\n",
    "    for p in tsvreader:\n",
    "        common_scope_code, level = get_scope_similarity_level(p[2],p[3])\n",
    "        level_distribution[level] += 1/len(sequence_pairs)\n",
    "level_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(sequences, scope_codes, prefix=\"train\", nsets=100, npairs=100000):\n",
    "    scope_pairs = generate_scope_pairs(scope_codes)\n",
    "    scope_pair_cdf, scope_pair_pdf = compute_scope_pair_cdf(scope_pairs, lambda x: np.power(x, 0.75))\n",
    "    for seti in range(nsets):\n",
    "        with open(f\"../../data/{prefix}_set_{seti}.tsv\", \"w\") as fout:\n",
    "            tsvwriter = csv.writer(fout, delimiter='\\t')\n",
    "            for i in run_sampling(np.array([i[1] for i in scope_pair_cdf]), n=npairs):\n",
    "                scope_code, _ = scope_pair_cdf[i]\n",
    "                pairs = scope_pairs[scope_code]\n",
    "                pairi = np.random.randint(0,len(pairs), None)\n",
    "                i1, i2 = pairs[pairi]\n",
    "                common_scope_code, common_level = get_scope_similarity_level(scope_codes[i1],\n",
    "                                                                             scope_codes[i2])\n",
    "                tpl = (sequences[i1], \n",
    "                        sequences[i2], \n",
    "                        scope_codes[i1], \n",
    "                        scope_codes[i2],\n",
    "                       common_level,\n",
    "                      )\n",
    "                tsvwriter.writerow(tpl)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
